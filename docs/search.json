[
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archivo",
    "section": "",
    "text": "How to Create an Alluvial Plot in Stata\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\n\n\n\n\n\n\nInteractive List of Japanese Words Using R Shiny Apps\n\n\n\n\n\n\n\n\n\nMar 6, 2024\n\n\n\n\n\n\n\n\nLoading and Exploring Japanese Kanji Data Using R\n\n\n\n\n\n\n\n\n\nFeb 27, 2024\n\n\n\n\n\n\n\n\nHow to Create an Aluvial Plot in R\n\n\n\n\n\n\n\n\n\nFeb 22, 2024\n\n\n\n\n\n\n\n\nLasso Regression\n\n\n\n\n\n\n\n\n\nFeb 6, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nHow to Create an Alluvial Plot in Stata\n\n\n\n\n\n\n\nStata\n\n\nplot\n\n\nalluvial\n\n\n\n\nHow to draw an Alluvial Plot in Stata with example code.\n\n\n\n\n\n\nMar 11, 2024\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nInteractive List of Japanese Words Using R Shiny Apps\n\n\n\n\n\n\n\nR\n\n\nshiny\n\n\nexploratory\n\n\n\n\nUsing R Shiny to interactively explore data, with a Japanese Kanji database example.\n\n\n\n\n\n\nMar 6, 2024\n\n\n17 min\n\n\n\n\n\n\n  \n\n\n\n\nLoading and Exploring Japanese Kanji Data Using R\n\n\n\n\n\n\n\nR\n\n\ndata cleaning\n\n\nexploratory\n\n\n\n\nUsing R to load, explore, describe, and filter data, with a Japanese Kanji database example.\n\n\n\n\n\n\nFeb 27, 2024\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nHow to Create an Aluvial Plot in R\n\n\n\n\n\n\n\nggplot\n\n\nplot\n\n\nalluvial\n\n\nR\n\n\n\n\nHow to draw an Alluvial Plot in R with example code.\n\n\n\n\n\n\nFeb 22, 2024\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nLasso Regression\n\n\n\n\n\n\n\nregression\n\n\nR\n\n\nlasso\n\n\n\n\nWhat is, what is it used for, and how to use Lasso regression, with code in R.\n\n\n\n\n\n\nFeb 6, 2024\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EpiStats",
    "section": "",
    "text": "Hello there! I’m Carlos Fernández, MD, MPH, and I’m passionate about biostatistics, epidemiology, and programming.\nHere, I’ll share whatever I learn along the way regarding statistics, scientific methods, and coding in R, Stata, or Python.\nYou can reach me at carlosepistats@gmail.com\nThank you for stopping by!"
  },
  {
    "objectID": "posts/ggplot2-tips/ggplot-series.html",
    "href": "posts/ggplot2-tips/ggplot-series.html",
    "title": "Series: ggplot2-tips",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "posts/new_blog_post/post.html",
    "href": "posts/new_blog_post/post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/new_blog_post/post.html#merriweather",
    "href": "posts/new_blog_post/post.html#merriweather",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]"
  },
  {
    "objectID": "posts/new_blog_post/post.html#columns",
    "href": "posts/new_blog_post/post.html#columns",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "geom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)"
  },
  {
    "objectID": "posts/new_blog_post/post.html#margin-captions",
    "href": "posts/new_blog_post/post.html#margin-captions",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/lasso_regression/post.html",
    "href": "posts/lasso_regression/post.html",
    "title": "Lasso Regression",
    "section": "",
    "text": "In this post, I explain what Lasso regression is, what it is used for, and how to use it, with code in R.\n\n\nLasso regression is a modified version of linear regression whose objective is to find the simplest model possible. In order to do that, Lasso method penalizes large regression coefficients, leaving smaller coefficients and even removing some variables from the final model (i.e., setting their coefficients to zero).\nLasso is an acronym of Least Absolute Shrinkage and Selector Operator.\n\n\n\nLasso regression is used mainly in two applications:\n\nModel variable selection: Lasso can be used as a method to select the most important variables in a regression model. The least important variables will have their coefficients set to zero, effectively being removed from the final model.\nParameter shrinkage: Lasso’s coefficients are smaller thant those of a simple lineal regression. This helps to avoid overfitting problems.\n\nGiven their two main functions, Lasso regression is usually employed in the following situations:\n\nWhen we have a high-dimensionality dataset, i.e., with a large number of variables.\nWhen we have multicolineallity in our model, i.e., several variables are lineally dependent of one another.\nWhen we want to automatize the model building, via automatizing the selection of the included variables.\n\n\n\n\nA traditional multivariable lineal regression model finds a set of regression coefficients (\\(\\beta_0, \\beta_1, \\beta_2...\\)) that minimizes the residuals’ squared sum (RSS). That is, the distance between the datapoints and the model predictions.\nLasso regression adds another parameter called L1. L1 is defined as the sum of the absolute values of the model coefficients. Lasso method tries to minimize the sum of RSS and L1. As a consequence, Lasso finds a model with smaller regression coefficients. This whole process is known as “L1 regularization”, and it produces a coefficient “shrinkage”.\nEvery time we run a Lasso regression, whe need to specify the lambda parameter (\\(\\lambda\\)). Lambda represents the relative importance of the L1 parameter compared to the RSS part of the minimization formula.\n\nWith \\(\\lambda = 0\\), there is no coefficient shrinkage, and the Lasso model is effectively equal to a regular linear regression model.\nAs \\(\\lambda\\) grows, there is more shrinkage, and more variables are removed from the model.\nIf \\(\\lambda\\) were to be infinite, all coefficients would be removed, and we would end up with an empty model.\n\n\n\n\\(min(RSS + \\lambda \\sum |\\beta_j|)\\)\nWhere\n\n\\(RSS\\) is the residuals’ square sum.\n\\(\\lambda\\) is Lasso’s penalizing factor.\n\\(\\sum |\\beta_j|\\) is the sum of the absolute values of the regression coefficients."
  },
  {
    "objectID": "posts/lasso_regression/post.html#qué-es-la-regresión-lasso",
    "href": "posts/lasso_regression/post.html#qué-es-la-regresión-lasso",
    "title": "Regresión Lasso",
    "section": "",
    "text": "La regresión Lasso es una variante de la regresión lineal que busca obtener un modelo lo más simple posible. Para ello, penaliza los modelos con coeficientes grandes, dejando coeficientes pequeños e incluso eliminando variables del modelo (igualando sus coeficientes a cero).\nLasso es un acrónimo de Least Absolute Shrinkage and Selector Operator."
  },
  {
    "objectID": "posts/lasso_regression/post.html#para-qué-se-usa-la-regresión-lasso",
    "href": "posts/lasso_regression/post.html#para-qué-se-usa-la-regresión-lasso",
    "title": "Regresión Lasso",
    "section": "",
    "text": "Lasso tiene dos funciones principales:\n\nSelección de variables para un modelo: como puede convertir los coeficientes de las variables en ceros, puede usarse para seleccionar las variables más importantes del modelo y excluir otras.\nContracción de parámetros (shrinkage): los coeficientes del modelo Lasso son más pequeños que en una regresión lineal normal. Esto ayuda al reducir el peligro de sobreajuste (overfitting) del modelo."
  },
  {
    "objectID": "posts/lasso_regression/post.html#cuándo-se-usa-la-regresión-lasso",
    "href": "posts/lasso_regression/post.html#cuándo-se-usa-la-regresión-lasso",
    "title": "Regresión Lasso",
    "section": "",
    "text": "Lasso se suele utilizar en las siguientes situaciones:\n\nCuando tenemos bases de datos con alta dimensionalidad(con muchas variables).\nCuando tenemos modelos con multicolinealidad.\nCuando queremos automatizar la construcción de un modelo (automatizando la selección de variables)."
  },
  {
    "objectID": "posts/lasso_regression/post.html#cómo-funciona-la-regresión-lasso",
    "href": "posts/lasso_regression/post.html#cómo-funciona-la-regresión-lasso",
    "title": "Regresión Lasso",
    "section": "",
    "text": "Un modelo de regresión lineal múltiple busca el conjunto de coeficientes (\\(\\beta_0, \\beta_1, \\beta_2...\\)) que minimiza la suma de los cuadrados de los residuales. Esto es, la distancia entre los datos y la predicción del modelo (residual) se eleva al cuadrado y se suma. El método de mínimos cuadrados de la regresión lineal busca minimizar esta suma.\nLa regresión Lasso añade otro parámetro conocido como L1. L1 es la suma de los valores absolutos de los coeficientes del modelo. Lasso busca minimizar la suma de L1 y la suma de cuadrados. Por lo tanto, Lasso busca el menor valor absoluto posible de los coeficientes, que se traduce en menor L1. Este proceso se llama “regularización L1”, y produce una “contracción” de los coeficientes (los hace más pequeños).\nToda regresión Lasso incluye un parámetro adicional, lambda (\\(\\lambda\\)). Lambda mide cuánta importancia le da el modelo al parámetro L1:\n\nSi \\(\\lambda = 0\\), no hay contracción de coeficientes y el modelo es equivalente a una regresión lineal normal.\nConforme \\(\\lambda\\) aumenta, hay más contracción de coeficientes y se eliminan más variables.\nSi \\(\\lambda\\) = infinito, hay contracción máxima y se eliminan todos los coeficientes."
  },
  {
    "objectID": "posts/lasso_regression/post.html#fórmula-de-la-regresión-lasso",
    "href": "posts/lasso_regression/post.html#fórmula-de-la-regresión-lasso",
    "title": "Regresión Lasso",
    "section": "",
    "text": "\\(min(RSS + \\lambda \\sum |\\beta_j|)\\)\nDonde\n\n\\(RSS\\) es la suma de residuos cuadrados.\n\\(\\lambda\\) es el parámetro de penalización de Lasso.\n\\(\\sum |\\beta_j|\\) es la suma de los valores absolutos de los coeficientes de las variables."
  },
  {
    "objectID": "posts/lasso_regression/post.html#preparativos",
    "href": "posts/lasso_regression/post.html#preparativos",
    "title": "Regresión Lasso",
    "section": "Preparativos",
    "text": "Preparativos\nPara este ejemplo, usaremos la biblioteca glmnet y la biblioteca de ejemplo mtcars.\n\n# install.packages(\"glmnet\") # Instalar el paquete\nlibrary(glmnet)\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nUsaremos mpg (millas por galón) como la variable resultado, y cyl (nº. de cilindros), hp (caballos de vapor), wt (peso), gear (nº. de marchas) y drat (relación del eje) como predictoras.\n\n# definir la variable resultado\ny &lt;- mtcars$mpg\n\n# definir las variables predictoras\nx &lt;- data.matrix(mtcars[, c(\"cyl\", \"hp\", \"wt\", \"drat\", \"gear\")])"
  },
  {
    "objectID": "posts/lasso_regression/post.html#elegir-el-valor-de-lambda",
    "href": "posts/lasso_regression/post.html#elegir-el-valor-de-lambda",
    "title": "Regresión Lasso",
    "section": "Elegir el valor de lambda",
    "text": "Elegir el valor de lambda\nPodemos elegir el valor de \\(\\lambda\\) que minimice el error cuadrado medio (mean-squared error, MSE). La función cv.glmnet() realiza “validación cruzada de k iteraciones” (K-fold cross-validation) para identificar este valor de \\(\\lambda\\).\n\n# validación cruzada\ncv_model &lt;- cv.glmnet(x, y, alpha = 1)  # Cambiar el parámetro alpha da lugar a otros tipos de regresión\n\n# encontrar el valor lambda que minimiza el MSE\nbest_lambda &lt;- cv_model$lambda.min\nbest_lambda\n\n[1] 0.2389017\n\n# mostrar los resultados en un gráfico\nplot(cv_model)\n\n\n\n\nEl valor de lambda que minimiza el MSE resulta ser 0.2389017, que en la gráfica corresponde al punto \\(Log(\\lambda)\\) = -1.4317031."
  },
  {
    "objectID": "posts/lasso_regression/post.html#correr-el-modelo",
    "href": "posts/lasso_regression/post.html#correr-el-modelo",
    "title": "Regresión Lasso",
    "section": "Correr el modelo",
    "text": "Correr el modelo\n\n# coeficientes del modelo \nbest_model &lt;- glmnet(x, y, alpha = 1, lambda = best_lambda)\ncoef(best_model)\n\n6 x 1 sparse Matrix of class \"dgCMatrix\"\n                     s0\n(Intercept) 35.74777065\ncyl         -0.83999245\nhp          -0.01680443\nwt          -2.89776526\ndrat         0.36928132\ngear         .         \n\n\nPodemos observar como el coeficiente de gear aparece como un punto, lo que indica que la regresión Lasso ha eliminado el coeficiente, ya que la variable no era lo suficientemente importante."
  },
  {
    "objectID": "posts/lasso_regression/post.html#comparación-con-la-regresión-lineal-sin-lasso",
    "href": "posts/lasso_regression/post.html#comparación-con-la-regresión-lineal-sin-lasso",
    "title": "Lasso regression",
    "section": "Comparación con la regresión lineal sin Lasso",
    "text": "Comparación con la regresión lineal sin Lasso\nComo comparación, podemos ver los coeficientes que resultarían de un modelo de regresión lineal múltiple sin contracción de parámetros ni selección de variables.\n\nlinear_model &lt;- lm(mpg ~ cyl + hp + wt + drat + gear, data = mtcars)\ncbind(coef(best_model), \"Linear\" = coef(linear_model))\n\n6 x 2 sparse Matrix of class \"dgCMatrix\"\n                     s0      Linear\n(Intercept) 35.74777065 33.99417771\ncyl         -0.83999245 -0.72169272\nhp          -0.01680443 -0.02227636\nwt          -2.89776526 -2.92715539\ndrat         0.36928132  0.73105753\ngear         .           0.16750690\n\n\nLos coeficientes del modelo Lasso se han contraído un poco, especialmente de la variable drat, y la variable gear ha sido automáticamente excluida."
  },
  {
    "objectID": "posts/dummy_post/post.html",
    "href": "posts/dummy_post/post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/dummy_post/post.html#merriweather",
    "href": "posts/dummy_post/post.html#merriweather",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]"
  },
  {
    "objectID": "posts/dummy_post/post.html#columns",
    "href": "posts/dummy_post/post.html#columns",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "geom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)"
  },
  {
    "objectID": "posts/dummy_post/post.html#margin-captions",
    "href": "posts/dummy_post/post.html#margin-captions",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/lasso_regression/post.html#ajustar-el-modelo",
    "href": "posts/lasso_regression/post.html#ajustar-el-modelo",
    "title": "Lasso regression",
    "section": "Ajustar el modelo",
    "text": "Ajustar el modelo\n\n# coeficientes del modelo \nbest_model &lt;- glmnet(x, y, alpha = 1, lambda = best_lambda)\ncoef(best_model)\n\n6 x 1 sparse Matrix of class \"dgCMatrix\"\n                     s0\n(Intercept) 35.74777065\ncyl         -0.83999245\nhp          -0.01680443\nwt          -2.89776526\ndrat         0.36928132\ngear         .         \n\n\nPodemos observar como el coeficiente de gear aparece como un punto, lo que indica que la regresión Lasso ha eliminado el coeficiente, ya que la variable no era lo suficientemente importante."
  },
  {
    "objectID": "dummy_post/post.html",
    "href": "dummy_post/post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "dummy_post/post.html#merriweather",
    "href": "dummy_post/post.html#merriweather",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]"
  },
  {
    "objectID": "dummy_post/post.html#columns",
    "href": "dummy_post/post.html#columns",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "geom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)"
  },
  {
    "objectID": "dummy_post/post.html#margin-captions",
    "href": "dummy_post/post.html#margin-captions",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/alluvial_plot/post.html",
    "href": "posts/alluvial_plot/post.html",
    "title": "How to Create an Aluvial Plot in R",
    "section": "",
    "text": "In this post, I explain how to create an alluvial plot using code in R\n\n\nAn alluvial diagram or plot displays the flow of information from one categorical variable or stage to the next. The term “alluvial” refers to its resemblance to the flow of a river.\n\n\n\nAlluvial diagrams are commonly used in the following situations:\n\nTo demonstrate the number of participants in a study transitioning from one baseline category to a subsequent category. For example, the number of participants randomized at the beginning of the study and who continue to follow-up at the end. It serves as a graphical supplement to flowcharts, which present information with arrows and boxes containing text and numbers.\nTo show the distribution of participants among different categorical variables. In this case, it provides a more “visually appealing” alternative to stacked column charts."
  },
  {
    "objectID": "posts/alluvial_plot/post.html#qué-es-un-diagrama-aluvial",
    "href": "posts/alluvial_plot/post.html#qué-es-un-diagrama-aluvial",
    "title": "Diagrama aluvial (alluvial plot)",
    "section": "",
    "text": "Un diagrama o gráfico aluvial muestra el flujo de información de un estadio al siguiente. El nombre “aluvial” alude a su parecido con el flujo de un río."
  },
  {
    "objectID": "posts/alluvial_plot/post.html#para-qué-se-usan-los-diagramas-aluviales",
    "href": "posts/alluvial_plot/post.html#para-qué-se-usan-los-diagramas-aluviales",
    "title": "Diagrama aluvial (alluvial plot)",
    "section": "",
    "text": "Un diagrama aluvial se suele utilizar en las siguientes situaciones:\n\nPara mostrar el número de participantes de un estudio que cambian desde una categoría basal a una categoría siguiente. Por ejemplo, el número de participantes aleatorizados al principio del estudio y que continúan en seguimiento al final. Es un complemento gráfico a los diagramas de flujo, que presentan la información con flechas y cajas con texto y números.\nPara mostrar la distribución de participantes entre distintas variables categóricas. En este caso es una alternativa más “vistosa” a los diagramas de columnas apilados."
  },
  {
    "objectID": "posts/alluvial_plot/post.html#preparativos",
    "href": "posts/alluvial_plot/post.html#preparativos",
    "title": "How to Create an Aluvial Plot in R",
    "section": "Preparativos",
    "text": "Preparativos\nFor this example, we will use the ggalluvial and ggplot2 libraries. The data come from a study on language learning using the web application LingQ (Link to the article).\n\n\nShow the code\n# Load necessary libraries\nlibrary(tidyverse) # Includes ggplot2\nlibrary(ggalluvial)\nlibrary(knitr)\n\n# Input data\n\ndata &lt;- data.frame(\n  Initial = rep(c(\"First\", \"Second\", \"Third\", \"Fourth+\"), each = 4),\n  Final = rep(c(\"First\", \"Second\", \"Third\", \"Fourth+\"), 4), \n  Frequency = c(28, 28, 10, 4, 3, 6, 7, 5,  0, 3, 3, 3, 0, 0, 0, 1)\n) %&gt;% \n  mutate(\n    Initial = factor(Initial, levels = c(\"First\", \"Second\", \"Third\", \"Fourth+\")),\n    Final = factor(Final, levels = c(\"First\", \"Second\", \"Third\", \"Fourth+\"))\n  )\n\nhead(data)\n\n\n  Initial   Final Frequency\n1   First   First        28\n2   First  Second        28\n3   First   Third        10\n4   First Fourth+         4\n5  Second   First         3\n6  Second  Second         6\n\n\nIn this study, a total of 192 individuals were selected for the sample and completed the initial knowledge test. Out of these, 101 completed the final test and studied for at least two hours in the application, and were included in the analysis. The data show the equivalent language knowledge in formal education semesters (“First”, “Second”, “Third”, “Fourth or more”) at the beginning of the study (“Initial”) and after using the application (“Final”).\nNote: The data have been extracted from the example article from the result tables and are just an example of a data distribution compatible with those results."
  },
  {
    "objectID": "posts/alluvial_plot/post.html#gráfico",
    "href": "posts/alluvial_plot/post.html#gráfico",
    "title": "Diagrama aluvial (alluvial plot)",
    "section": "Gráfico",
    "text": "Gráfico\n\n# Diagrama aluvial\ndata %&gt;% \nggplot(aes(axis1 = fct_rev(Inicial), axis2 = fct_rev(Final),\n           y = Frecuencia)) +\n  scale_x_discrete(limits = c(\"Inicial\", \"Final\"), expand = c(.2, .05)) +\n  geom_alluvium(aes(fill = Final)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_minimal() +\n  labs(x = \"Semestres equivalentes de educación formal\")\n\n\n\n\nEn el diagrama aluvial, el área de las zonas coloreadas es proporcional a la frecuencia, por lo que “flujos” más anchos representan más participantes.\nEn el gráfico se aprecia cómo la mayor parte del flujo ocurre de abajo arriba; es decir, el conocimiento tiende a mejorar más que a empeorar. Por ejemplo, más de la mitad de los participantes que partían del primer semestre de conocimientos subieron al segundo, tercer o cuarto semestre.\nTambién se puede ver como casi todos los participantes que acabaron con un nivel de conocimientos equivalente al primer semestre partían de ese nivel previo, y unos pocos bajaron del segundo semestre al primer semestre.\nEn definitiva, los diagramas aluviales proporcionan una opción visual para entender mejor los flujos de datos entre categorías, especialmente si hay algún componente temporal asociado a ellas."
  },
  {
    "objectID": "posts/lasso_regression/post.html#what-is-lasso-regression",
    "href": "posts/lasso_regression/post.html#what-is-lasso-regression",
    "title": "Lasso Regression",
    "section": "",
    "text": "Lasso regression is a modified version of linear regression whose objective is to find the simplest model possible. In order to do that, Lasso method penalizes large regression coefficients, leaving smaller coefficients and even removing some variables from the final model (i.e., setting their coefficients to zero).\nLasso is an acronym of Least Absolute Shrinkage and Selector Operator."
  },
  {
    "objectID": "posts/lasso_regression/post.html#what-is-lasso-regression-used-for",
    "href": "posts/lasso_regression/post.html#what-is-lasso-regression-used-for",
    "title": "Lasso Regression",
    "section": "",
    "text": "Lasso regression is used mainly in two applications:\n\nModel variable selection: Lasso can be used as a method to select the most important variables in a regression model. The least important variables will have their coefficients set to zero, effectively being removed from the final model.\nParameter shrinkage: Lasso’s coefficients are smaller thant those of a simple lineal regression. This helps to avoid overfitting problems.\n\nGiven their two main functions, Lasso regression is usually employed in the following situations:\n\nWhen we have a high-dimensionality dataset, i.e., with a large number of variables.\nWhen we have multicolineallity in our model, i.e., several variables are lineally dependent of one another.\nWhen we want to automatize the model building, via automatizing the selection of the included variables."
  },
  {
    "objectID": "posts/lasso_regression/post.html#how-does-lasso-regression-work",
    "href": "posts/lasso_regression/post.html#how-does-lasso-regression-work",
    "title": "Lasso Regression",
    "section": "",
    "text": "A traditional multivariable lineal regression model finds a set of regression coefficients (\\(\\beta_0, \\beta_1, \\beta_2...\\)) that minimizes the residuals’ squared sum (RSS). That is, the distance between the datapoints and the model predictions.\nLasso regression adds another parameter called L1. L1 is defined as the sum of the absolute values of the model coefficients. Lasso method tries to minimize the sum of RSS and L1. As a consequence, Lasso finds a model with smaller regression coefficients. This whole process is known as “L1 regularization”, and it produces a coefficient “shrinkage”.\nEvery time we run a Lasso regression, whe need to specify the lambda parameter (\\(\\lambda\\)). Lambda represents the relative importance of the L1 parameter compared to the RSS part of the minimization formula.\n\nWith \\(\\lambda = 0\\), there is no coefficient shrinkage, and the Lasso model is effectively equal to a regular linear regression model.\nAs \\(\\lambda\\) grows, there is more shrinkage, and more variables are removed from the model.\nIf \\(\\lambda\\) were to be infinite, all coefficients would be removed, and we would end up with an empty model.\n\n\n\n\\(min(RSS + \\lambda \\sum |\\beta_j|)\\)\nWhere\n\n\\(RSS\\) is the residuals’ square sum.\n\\(\\lambda\\) is Lasso’s penalizing factor.\n\\(\\sum |\\beta_j|\\) is the sum of the absolute values of the regression coefficients."
  },
  {
    "objectID": "posts/lasso_regression/post.html#getting-ready",
    "href": "posts/lasso_regression/post.html#getting-ready",
    "title": "Lasso Regression",
    "section": "Getting Ready",
    "text": "Getting Ready\nIn this example, we’ll use the glmnet library and the example dataset in mtcars.\n\n\nShow the code\n# install.packages(\"glmnet\") # Install the package (only once)\nlibrary(glmnet)\nhead(mtcars)\n\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nWe’ll use mpg (miles per galon) as the outcome variable, and cyl (number of cylinders), hp (horsepower), wt (weight), gear (gear number), and drat (rear axle ratio) as predictive variables.\n\n\nShow the code\n# Define the outcome variable\ny &lt;- mtcars$mpg\n\n# Define the predictive variables\nx &lt;- data.matrix(mtcars[, c(\"cyl\", \"hp\", \"wt\", \"drat\", \"gear\")])"
  },
  {
    "objectID": "posts/lasso_regression/post.html#choose-a-value-for-lambda",
    "href": "posts/lasso_regression/post.html#choose-a-value-for-lambda",
    "title": "Lasso Regression",
    "section": "Choose a Value for Lambda",
    "text": "Choose a Value for Lambda\nWe can choose the value of \\(\\lambda\\) that minimizes the mean-squared error (MSE). The cv.glmnet() function performs “K-fold cross-validation” to identify this \\(\\lambda\\) value.\n\n\nShow the code\n# Cross-validation\ncv_model &lt;- cv.glmnet(x, y, alpha = 1)  # Changing the alpha parameter leads to other types of regression\n\n# Find the lambda value that minimizes the MSE\nbest_lambda &lt;- cv_model$lambda.min\nbest_lambda\n\n\n[1] 0.3803991\n\n\nShow the code\n# Display the results in a plot\nplot(cv_model)\n\n\n\n\n\nThe value of lambda that minimizes the MSE turns out to be 0.3803991, which in the plot corresponds to the point \\(Log(\\lambda)\\) = -0.9665344."
  },
  {
    "objectID": "posts/kanji/post.html",
    "href": "posts/kanji/post.html",
    "title": "Loading and Exploring Japanese Kanji Data Using R",
    "section": "",
    "text": "Introduction\nIn this blog post, I’ll demonstrate how to use R to load, explore, and filter data from a dataset containing Japanese characters, known as “kanji”. The datasets were obtained from an online Kanji database. We’ll focus on using the tidyverse family of packages to illustrate how to select and filter relevant information efficiently.\n\n\nSetup and Loading\nTo begin, we need to load necessary libraries and import the datasets:\n\n# | warning: false\n# Loading necessary libraries\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\n# Loading datasets\n\ndata_kanji &lt;- read.csv2(here(\"data/kanji\", \"Kanji_20240227_081842.csv\")) %&gt;% \n  clean_names()\n\ndata_jukugo &lt;- read.csv2(here(\"data/kanji\", \"Jukugo_20240227_081908.csv\")) %&gt;% \n  clean_names()\n\nHere’s a breakdown of the code:\n\nlibrary(tidyverse): We load the tidyverse package, which includes dplyr, ggplot2, and other useful packages.\nlibrary(here): This package helps manage file paths conveniently.\nlibrary(janitor): Useful for standardizing variable names and data cleaning.\nWe use read.csv2() to import CSV (comma-separated value) files with semicolons (;) as separators.\nhere(\"data/kanji\", \"Kanji_20240227_081842.csv\") uses the function here() to access the data file, which is saved inside the folders data &gt; kanji.\nThe characters %&gt;% are called a “pipe” in tidyverse. It can be written simply by pressing Ctrl + Shift + M (in Windows). Basically, it tells R that we want to apply some step to the previous data. In this example, I tell R that I want to use the function clean_names() to the data that I’ve already loaded using read.csv2().\nclean_names() is a janitor function that renames all variables in a standard format to make it easier to manipulate. Specifically, clean_names() sets all names to lowercase, removes punctuation and symbols, and replaces spaces with underscores.\n\nNow I have two separate datasets: one for kanji (single characters), and one for jukugo (compound words). Let’s take a look at them.\n\n\nExploring the data\nLet’s examine the first few rows of each dataset:\n\nhead(data_kanji)\n\n    id kanji strokes grade\n1   41    一       1     1\n2  124    乙       1     7\n3 2060    了       2     7\n4 2074    力       2     1\n5 1577    二       2     1\n6 1070    人       2     1\n\nhead(data_jukugo)\n\n   id comp_word frequency          grammatical_feature pronunciation\n1 173      一部     46289 possible to use as an adverb         itibu\n2 234      一般     39274                 general noun         ippan\n3 432      一時     25126 possible to use as an adverb         itizi\n4 461      一番     24155 possible to use as an adverb        itiban\n5 481      一緒     23453    light-verb -suru attached         issyo\n6 529      一致     21388    light-verb -suru attached          itti\n  english_translation position kanji kanji_id\n1            one part        L    一       41\n2             general        L    一       41\n3         one o'clock        L    一       41\n4                best        L    一       41\n5            together        L    一       41\n6         coincidence        L    一       41\n\n\nWe’re using the base function head()to show the first rows or observations of our datasets.\nWe can see that data_kanji has four columns or variables:\n\nid shows a unique identification number.\nkanji stores the actual character.\nstrokes represents the number of distinct lines or strokes that the character has.\ngrade means the official categorization of Kanji by educational year in Japan. Grade 1 includes the easiest or most common kanji, and it goes all up to grade 7.\n\nOn the other hand, data_jukugo contains nine variables:\n\nid is the identification number for jukugos.\ncomp_word is the actual word.\nfrequency is a measure of how many times each jukugo appear in a selected corpus of Japanese literature (extracted from Japanese newspapers).\ngrammatical_feature gives us more context of how the word is used in grammatical terms.\npronunciation tells us the pronunciation in “romaji”, or the Latin alphabet.\nenglish_translation stores the English translation.\n\nThe last three variables in data_jukugo describes the kanji which is part of the jukugo:\n\nposition tells us if the kanji is used in left position “L” or right position “R”.\nkanji shows the kanji used in the jukugo. The first rows all show jukugos composed with the kanji “一”.\nkanji_id is the identification number of the kanji part. We can use this id to link data_jukugo with data_kanji if we want to.\n\nAnother way of looking into a dataset is to explore how each variable is encoded:\n\nglimpse(data_kanji)\n\nRows: 2,136\nColumns: 4\n$ id      &lt;int&gt; 41, 124, 2060, 2074, 1577, 1070, 1584, 829, 359, 1647, 1903, 1…\n$ kanji   &lt;chr&gt; \"一\", \"乙\", \"了\", \"力\", \"二\", \"人\", \"入\", \"七\", \"九\", \"八\", \"…\n$ strokes &lt;int&gt; 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,…\n$ grade   &lt;int&gt; 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 7, 3, 1, 2, 1, 2, 6, 7, 6, 1, 2,…\n\nglimpse(data_jukugo)\n\nRows: 52,791\nColumns: 9\n$ id                  &lt;int&gt; 173, 234, 432, 461, 481, 529, 937, 1465, 1521, 156…\n$ comp_word           &lt;chr&gt; \"一部\", \"一般\", \"一時\", \"一番\", \"一緒\", \"一致\", \"…\n$ frequency           &lt;int&gt; 46289, 39274, 25126, 24155, 23453, 21388, 12477, 7…\n$ grammatical_feature &lt;chr&gt; \"possible to use as an adverb\", \"general noun\", \"p…\n$ pronunciation       &lt;chr&gt; \"itibu\", \"ippan\", \"itizi\", \"itiban\", \"issyo\", \"itt…\n$ english_translation &lt;chr&gt; \"one part\", \"general\", \"one o'clock\", \"best\", \"tog…\n$ position            &lt;chr&gt; \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", …\n$ kanji               &lt;chr&gt; \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"…\n$ kanji_id            &lt;int&gt; 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41…\n\n\nThe glimpse() function allows us to quickly glance at the data structure.\nWe can see that data_kanji has 2,136 rows or observations and 4 columns or variables. We also see the first values of each of its four variables. More importantly, we can see which data type each variable stores. The kanji variable has &lt;chr&gt; type, which means “character” or “text”, while the rest of variables have &lt;int&gt; type, which means “integer” number, or a round number. R automatically detects the data types when importing data using functions like read.csv2().\nRegarding data_jukugo, it has 52,791 rows and 9 columns, of which 3 have &lt;int&gt; type, and 6 have &lt;char&gt; type.\n\n\nManipulating the data\nNow that I’m familiarized with this dataset, it’s useful to lay down what my analysis plan is. In other words, what do I want to learn from this data? In this case, I want to be able to find words (jukugo) that only contain kanji from a selected list of kanji that I’m learning. So, for example, if I only know kanjis 一, 人, and 十, I want to know all the possible combinations of these three kanjis.\nFor this exercise, I’m interested in separating jukugos in two parts: the left kanji, and the right kanji. The dataset already has half of this information, but sometimes it tells us the left kanji, and sometimes the right kanji (more on this later). I want to get sistematically both left and right kanjis in the same row, so I’ll create new variables called kanji_left and kanji_right.\n\ndata_jukugo &lt;- data_jukugo %&gt;% \n  mutate(kanji_left = substr(comp_word, 1, 1),\n         kanji_right = substr(comp_word, 2, 2))\n\nglimpse(data_jukugo)\n\nRows: 52,791\nColumns: 11\n$ id                  &lt;int&gt; 173, 234, 432, 461, 481, 529, 937, 1465, 1521, 156…\n$ comp_word           &lt;chr&gt; \"一部\", \"一般\", \"一時\", \"一番\", \"一緒\", \"一致\", \"…\n$ frequency           &lt;int&gt; 46289, 39274, 25126, 24155, 23453, 21388, 12477, 7…\n$ grammatical_feature &lt;chr&gt; \"possible to use as an adverb\", \"general noun\", \"p…\n$ pronunciation       &lt;chr&gt; \"itibu\", \"ippan\", \"itizi\", \"itiban\", \"issyo\", \"itt…\n$ english_translation &lt;chr&gt; \"one part\", \"general\", \"one o'clock\", \"best\", \"tog…\n$ position            &lt;chr&gt; \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", …\n$ kanji               &lt;chr&gt; \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"…\n$ kanji_id            &lt;int&gt; 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41…\n$ kanji_left          &lt;chr&gt; \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"一\", \"…\n$ kanji_right         &lt;chr&gt; \"部\", \"般\", \"時\", \"番\", \"緒\", \"致\", \"定\", \"連\", \"…\n\n\nLet’s explain the code:\n\nmutate() is the dplyr function used to create or change variables. Here, I create two variables, kanji_left and kanji_right.\nsubstr() is a base function that subtracts a string of text from a character variable. substr(comp_word, 1, 1) means to subtract only the first character, and substr(comp_word, 2, 2) gets the second character.\n\nAlright, now I need to define the list of kanjis that I’m currently learning. This I need to do it manually, but later I’ll explain how to do it more dinamically.\n\nkanji_learning &lt;- c(\"一\", \"二\", \"三\", \"王\", \"玉\", \"十\", \"五\")\n\nLastly, I’ll tell R to filter the jukugos that only include kanji that are on my learning list. I also want to sort the jukugos from more to less used.\n\njukugo_learning &lt;- data_jukugo %&gt;% \n  filter(kanji_left %in% kanji_learning, kanji_right %in% kanji_learning) %&gt;% \n  arrange(desc(frequency))\n\nhead(jukugo_learning)\n\n     id comp_word frequency          grammatical_feature pronunciation\n1 17059      二三        32 possible to use as an adverb         nisan\n2 17059      二三        32 possible to use as an adverb         nisan\n3 20330      三一        12                 general noun        sanpin\n4 20330      三一        12                 general noun        sanpin\n5 23443      一一         4 possible to use as an adverb        itiiti\n6 23443      一一         4 possible to use as an adverb        itiiti\n  english_translation position kanji kanji_id kanji_left kanji_right\n1        two or three        L    二     1577         二          三\n2        two or three        R    三      744         二          三\n3 low-ranking samurai        R    一       41         三          一\n4 low-ranking samurai        L    三      744         三          一\n5          one-by-one        L    一       41         一          一\n6          one-by-one        R    一       41         一          一\n\n\nThe filter() function selects rows based on one or more conditions. I’ve passed two conditions: that kanji_left is included in the kanji_learning “list” (in R we’d call this a vector, not a list), and that kanji_right is also included in kanji_learning. The term “is included in” is represented in R with the operand %in%.\nThe arrange() function reorders the rows based on one or more variables. I’ve passed the argument desc(frequency) because I want the words to be sorted in descending order of frequency (from more to less frequency).\nHowever, something odd has happened: now we have two copies of each jukugo. There are complete duplicates in the dataset, with the only difference of which kanji appears in the variables position, kanji, and kanji_id. For example, “nisan” (二三) appears twice, one with position L, kanji 二, and kanji_id 1577, and another with position R, kanji 三, and kanji_id 744. This is something that I didn’t see first time I explored the dataset.\nI could have done things differently. Instead of splitting the jukugos manually, I could have performed a “self-join” of the duplicated rows. But one cool thing about data cleaning and analysis is that there are always different ways to reach the same goal. It’s an iterative process, and by trial and error I can learn a lot and find alternative methods of doing things.\nMoving forward, since I’m only interested in keeping one record of each jukugo, I can drop these duplicates. Aditionally, I’ll keep only the variables I’m interested in.\n\njukugo_learning &lt;- jukugo_learning %&gt;% \n  select(id, comp_word, frequency, grammatical_feature, pronunciation, english_translation, kanji_left, kanji_right) %&gt;%\n  distinct()\n\nhead(jukugo_learning)\n\n     id comp_word frequency          grammatical_feature pronunciation\n1 17059      二三        32 possible to use as an adverb         nisan\n2 20330      三一        12                 general noun        sanpin\n3 23443      一一         4 possible to use as an adverb        itiiti\n4 25773      二王         2                 general noun          nioo\n          english_translation kanji_left kanji_right\n1                two or three         二          三\n2         low-ranking samurai         三          一\n3                  one-by-one         一          一\n4 the two guardian Deva kings         二          王\n\n\nI’ve used two new dplyr functions: select() keeps some columns or variables, and distinct() keeps only non-duplicated rows.\nThe final result contains four distinct jukugos: 二三, 三一, 一一, and 二王. All of them are very low-frequency, with the most common of them appearing only 32 times.\n\n\nNext step: making it interactive\nSo far, I have created a code that filters Japanese kanji words based on whatever Kanji components I want. However, the whole process would be nicer if I had a way of selecting the data interactivelly, maybe pressing some buttons. We can do just that using R Shiny applications. Find how in this post!\n\n\nReferences\n\nKanji database."
  },
  {
    "objectID": "posts/kanji_app/post.html",
    "href": "posts/kanji_app/post.html",
    "title": "Interactive List of Japanese Words Using R Shiny Apps",
    "section": "",
    "text": "In a previous post, I demonstrated how to use R to load, explore, and filter data from a dataset containing Japanese characters, known as “kanji”.\nToday, we’ll focus on making that data exploration interactive using the R package shiny."
  },
  {
    "objectID": "posts/kanji_app/post.html#setup-and-loading-data",
    "href": "posts/kanji_app/post.html#setup-and-loading-data",
    "title": "Interactive List of Japanese Words Using R Shiny Apps",
    "section": "Setup and Loading Data",
    "text": "Setup and Loading Data\nTo begin, we need to load the necessary libraries and import the datasets. I’ll use five different datasets to form the whole “dictionary”:\n\nA list of kanji downloaded from Kanji database\nA list of jukugo (words composed by two kanji) downloaded from Kanji database\nA list of words obtained from an Anki deck from here\nA list of sentences obtained from an Anki deck from here\nA dataset of Japanese numbers from 0 to 100, created manually.\n\nEach dataset contains three columns: word (in kanji), pronunciation (in hiragana or romaji), and meaning (in English).\n\n\nShow the code\n# Loading necessary libraries ####\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(readxl)\nlibrary(writexl)\nlibrary(shiny)\nlibrary(DT)\nlibrary(flextable)\n\n# Loading datasets ####\n\nfile_kanji &lt;- \"Kanji_20240227_081842.csv\"\nfile_jukugo &lt;- \"Jukugo_20240227_081908.csv\"\nfile_words &lt;- \"Optimized Kore - Sheet1.csv\"\nfile_sentences1 &lt;- \"Sentences.xlsx\"\nfile_sentences2 &lt;- \"Sentences_core.xlsx\"\n\n## Kanji list ####\ndata_kanji &lt;- read.csv2(here(\"data/kanji\", file_kanji)) %&gt;% \n  clean_names()\n\n## Jukugo list ####\ndata_jukugo &lt;- read.csv2(here(\"data/kanji\", file_jukugo)) %&gt;% \n  clean_names() %&gt;% \n  arrange(desc(frequency)) %&gt;% \n  select(comp_word, pronunciation, english_translation) %&gt;%\n  rename(word = comp_word,\n         meaning = english_translation) %&gt;% \n  distinct(word, .keep_all = TRUE) %&gt;% \n  # Change romaji\n  mutate(\n    pronunciation = gsub(\"zi\", \"ji\", pronunciation),\n    pronunciation = gsub(\"zy\", \"jy\", pronunciation),\n    pronunciation = gsub(\"ti\", \"chi\", pronunciation),\n    pronunciation = gsub(\"ty\", \"ch\", pronunciation),\n    pronunciation = gsub(\"si\", \"shi\", pronunciation),\n    pronunciation = gsub(\"sy\", \"shy\", pronunciation),\n    pronunciation = gsub(\"tu\", \"tsu\", pronunciation),\n    pronunciation = gsub(\"hu\", \"fu\", pronunciation)\n    )\n\n## word list ####\ndata_words &lt;- read.csv(here(\"data/kanji\", file_words)) %&gt;% \n  clean_names() %&gt;% \n  arrange(core_index) %&gt;% \n  select(vocab_expression, vocab_kana, vocab_meaning) %&gt;% \n  rename(word = vocab_expression,\n         pronunciation = vocab_kana,\n         meaning = vocab_meaning) %&gt;% \n  distinct(word, .keep_all = TRUE) \n\n## Number list ####\n\ndata_numbers &lt;- data.frame(\n  word = c(\"零\", \"一\", \"二\", \"三\", \"四\", \"五\", \"六\", \"七\", \"八\", \"九\", \"十\", \n     \"十一\", \"十二\", \"十三\", \"十四\", \"十五\", \"十六\", \"十七\", \"十八\", \"十九\", \n     \"二十\", \"二十一\", \"二十二\", \"二十三\", \"二十四\", \"二十五\", \"二十六\", \"二十七\", \n     \"二十八\", \"二十九\", \"三十\", \"三十一\", \"三十二\", \"三十三\", \"三十四\", \"三十五\", \n     \"三十六\", \"三十七\", \"三十八\", \"三十九\", \"四十\", \"四十一\", \"四十二\", \"四十三\", \n     \"四十四\", \"四十五\", \"四十六\", \"四十七\", \"四十八\", \"四十九\", \"五十\", \"五十一\", \n     \"五十二\", \"五十三\", \"五十四\", \"五十五\", \"五十六\", \"五十七\", \"五十八\", \"五十九\", \n     \"六十\", \"六十一\", \"六十二\", \"六十三\", \"六十四\", \"六十五\", \"六十六\", \"六十七\", \n     \"六十八\", \"六十九\", \"七十\", \"七十一\", \"七十二\", \"七十三\", \"七十四\", \"七十五\", \n     \"七十六\", \"七十七\", \"七十八\", \"七十九\", \"八十\", \"八十一\", \"八十二\", \"八十三\", \n     \"八十四\", \"八十五\", \"八十六\", \"八十七\", \"八十八\", \"八十九\", \"九十\", \"九十一\", \n     \"九十二\", \"九十三\", \"九十四\", \"九十五\", \"九十六\", \"九十七\", \"九十八\", \"九十九\", \"百\"),\n  pronunciation = c(\"れい\", \"いち\", \"に\", \"さん\", \"し\", \"ご\", \"ろく\", \"しち\", \"はち\", \"きゅう\", \"じゅう\",\n                    \"じゅういち\", \"じゅうに\", \"じゅうさん\", \"じゅうし\", \"じゅうご\", \"じゅうろく\", \"じゅうしち\", \"じゅうはち\", \"じゅうきゅう\",\n                    \"にじゅう\", \"にじゅういち\", \"にじゅうに\", \"にじゅうさん\", \"にじゅうし\", \"にじゅうご\", \"にじゅうろく\", \"にじゅうしち\", \"にじゅうはち\", \"にじゅうきゅう\",\n                    \"さんじゅう\", \"さんじゅういち\", \"さんじゅうに\", \"さんじゅうさん\", \"さんじゅうし\", \"さんじゅうご\", \"さんじゅうろく\", \"さんじゅうしち\", \"さんじゅうはち\", \"さんじゅうきゅう\",\n                    \"よんじゅう\", \"よんじゅういち\", \"よんじゅうに\", \"よんじゅうさん\", \"よんじゅうし\", \"よんじゅうご\", \"よんじゅうろく\", \"よんじゅうしち\", \"よんじゅうはち\", \"よんじゅうきゅう\",\n                    \"ごじゅう\", \"ごじゅういち\", \"ごじゅうに\", \"ごじゅうさん\", \"ごじゅうし\", \"ごじゅうご\", \"ごじゅうろく\", \"ごじゅうしち\", \"ごじゅうはち\", \"ごじゅうきゅう\",\n                    \"ろくじゅう\", \"ろくじゅういち\", \"ろくじゅうに\", \"ろくじゅうさん\", \"ろくじゅうし\", \"ろくじゅうご\", \"ろくじゅうろく\", \"ろくじゅうしち\", \"ろくじゅうはち\", \"ろくじゅうきゅう\",\n                    \"しちじゅう\", \"しちじゅういち\", \"しちじゅうに\", \"しちじゅうさん\", \"しちじゅうし\", \"しちじゅうご\", \"しちじゅうろく\", \"しちじゅうしち\", \"しちじゅうはち\", \"しちじゅうきゅう\",\n                    \"はちじゅう\", \"はちじゅういち\", \"はちじゅうに\", \"はちじゅうさん\", \"はちじゅうし\", \"はちじゅうご\", \"はちじゅうろく\", \"はちじゅうしち\", \"はちじゅうはち\", \"はちじゅうきゅう\",\n                    \"きゅうじゅう\", \"きゅうじゅういち\", \"きゅうじゅうに\", \"きゅうじゅうさん\", \"きゅうじゅうし\", \"きゅうじゅうご\", \"きゅうじゅうろく\", \"きゅうじゅうしち\", \"きゅうじゅうはち\", \"きゅうじゅうきゅう\",\n                    \"ひゃく\"),\n  meaning = as.character(0:100)\n  )\n\n# Sentence list ####\ndata_sentences1 &lt;- read_excel(here(\"data/kanji\", file_sentences1)) \ndata_sentences2 &lt;- read_excel(here(\"data/kanji\", file_sentences2))\n\ndata_sentences &lt;- rbind(data_sentences1, data_sentences2)\nrm(data_sentences1, data_sentences2)\n\n# Extract kana ####\n\nhiragana_chars &lt;- intToUtf8(seq(12353, 12438)) # Unicode range for hiragana characters\nkatakana_chars &lt;- intToUtf8(seq(12448, 12543)) # Unicode range for katakana characters\n\nkana &lt;- paste0(hiragana_chars, katakana_chars) %&gt;% \n  str_split_1(pattern = \"\") %&gt;% \n  paste(collapse = \"|\")\n\n\n# All data ####\ndata_bind &lt;- data_words %&gt;% \n  rbind(data_sentences %&gt;% select(word, pronunciation, meaning),\n        data_numbers,\n        data_jukugo) %&gt;% \n  mutate(word = str_remove_all(word, \"[ a-zA-Z]\")) %&gt;% \n  distinct(word, .keep_all = TRUE)\n\n# Extract kanji ####\n\nall_kanji &lt;- data_kanji %&gt;% \n  select(kanji) %&gt;% \n  rbind(data_bind %&gt;% \n          mutate(kanji = word, .keep = \"none\")) %&gt;% \n  mutate(kanji = str_remove_all(kanji, kana)) %&gt;% \n  filter(kanji != \"\") %&gt;% \n  pull() %&gt;% \n  paste(collapse = \"\") %&gt;% \n  str_split_1(pattern = \"\") %&gt;% \n  unique()\n  \n## Separate individual kanji from all words ####\ndata_all &lt;- data_bind %&gt;% \n  mutate(kanji = str_remove_all(word, kana)) %&gt;% \n  separate_wider_position(kanji, widths = c(\"kanji_1\" = 1, \n                                            \"kanji_2\" = 2,\n                                            \"kanji_3\" = 3,\n                                            \"kanji_4\" = 4,\n                                            \"kanji_5\" = 5),\n                          too_few = \"align_start\") %&gt;% \n  filter(!is.na(kanji_1))\n\nflextable(head(data_all))\n\n\n\nwordpronunciationmeaningkanji_1kanji_2kanji_3kanji_4kanji_5見るみるsee, look at見円えんcircle円多いおおいlots of多家うちhouse, home家新しいあたらしいnew新私わたしI私\n\n\nHere’s a breakdown of the final “dictionary”:\n\nword: This column contains the Japanese word.\npronunciation: It shows the pronunciation of the word.\nmeaning: This column provides the English translation or meaning of the word.\nkanji_1, kanji_2, kanji_3, kanji_4, kanji_5: These columns represents the kanji characters that compose each word.\n\nEach row corresponds to a different Japanese word, and the columns contain related information about each word, including its pronunciation, meaning in English, and associated kanji characters.\nFor example:\n\nThe word “見る” (miru) means “see, look at”, and its associated kanji is “見”.\nThe word “円” (en) means “circle”, and its associated kanji is “円”.\nThe word “多い” (ooi) means “lots of”, and its associated kanji is “多”."
  },
  {
    "objectID": "posts/kanji_app/post.html#shiny-app-code",
    "href": "posts/kanji_app/post.html#shiny-app-code",
    "title": "Interactive List of Japanese Words Using R Shiny Apps",
    "section": "Shiny App Code",
    "text": "Shiny App Code\n\n\nShow the code\n# Shiny App ####\n\nui &lt;- fluidPage(\n  \n  titlePanel(\"List Japanese Words Including Selected Kanji\"),\n  \n  sidebarLayout(\n    \n    sidebarPanel(\n      p(\"Created by CarlosEpiStats\"),\n      uiOutput(\"blog_link\"),\n      downloadButton(\"downloadExcel\", \"Download Excel file\"),\n      downloadButton(\"downloadCSV\", \"Download CSV file\"),\n      selectInput (\"kanji_selected\", \"Select Kanji:\",  \n                  choices = all_kanji, multiple = TRUE)\n\n    ),\n    \n    mainPanel(\n      \n      tabsetPanel(\n        \n        tabPanel(\n          \"List of words\",\n          textOutput(\"n_kanji\"),\n          textOutput(\"n_words\"),\n          DTOutput(\"table_words\")\n          ),\n        \n        tabPanel(\n          \"List of sentences\",\n          textOutput(\"n_sentences\"),\n          DTOutput(\"table_sentences\")\n        ),\n        \n        tabPanel(\n          \"Stats\",\n          tableOutput(\"number_words_per_kanji\")\n        )\n      )\n      \n      \n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  \n  # Blog link ####\n  url &lt;- a(\"CarlosEpiStats\", href=\"https://carlosepistats.github.io/blog/\")\n \n  output$blog_link &lt;- renderUI({\n    tagList(\"Blog:\", url)\n  })\n  \n  \n  # Reactive table words ####\n  rval_table_words &lt;- reactive({\n    study_table &lt;- make_study_list(input$kanji_selected)\n    study_table\n  })\n  \n  \n  # Reactive table sentences ####\n  rval_table_sentences &lt;- reactive({\n    study_table &lt;- make_sentences_list(input$kanji_selected)\n    study_table\n  })\n  \n  \n  # Reactive table counter ####\n  rval_table_counter &lt;- reactive({\n    \n    study_words &lt;- data_all %&gt;% \n      filter(kanji_1 %in% input$kanji_selected, \n             kanji_2 %in% input$kanji_selected | is.na(kanji_2),\n             kanji_3 %in% input$kanji_selected | is.na(kanji_3),\n             kanji_4 %in% input$kanji_selected | is.na(kanji_4),\n             kanji_5 %in% input$kanji_selected | is.na(kanji_5))\n    \n    learning_length &lt;- length(input$kanji_selected)\n    \n    kanji_counter &lt;- c()\n    \n    for (i in 1:learning_length){\n      \n      kanji_counter[i] &lt;- study_words %&gt;% \n        filter(kanji_1 %in% input$kanji_selected[i] | \n                 kanji_2 %in% input$kanji_selected[i] | \n                 kanji_3 %in% input$kanji_selected[i] |\n                 kanji_4 %in% input$kanji_selected[i] | \n                 kanji_5 %in% input$kanji_selected[i] ) %&gt;% \n        nrow()\n      \n    }\n    \n    table_counter &lt;- data.frame(kanji = input$kanji_selected,\n                                times = kanji_counter)\n    \n    table_counter\n    \n  })\n  \n  # Reactive number kanji ####\n  rval_n_kanji &lt;- reactive({\n    number_words &lt;- length(input$kanji_selected)\n    number_words\n  }) \n  \n  \n  # Reactive number words ####\n  rval_n_words &lt;- reactive({\n    study_table &lt;- rval_table_words()\n    number_words &lt;- nrow(study_table)\n    number_words\n  })\n  \n  # Reactive number sentences ####\n  rval_n_sentences &lt;- reactive({\n    study_table &lt;- rval_table_sentences()\n    number_sentences &lt;- nrow(study_table)\n    number_sentences\n  })\n  \n  # output number words ####\n  output$n_words &lt;- renderText({\n    n_words &lt;- rval_n_words()\n    paste0(\"Number of words: \", n_words)\n  })\n  \n  # output number Kanji ####\n  output$n_kanji &lt;- renderText({\n    number_kanji &lt;- rval_n_kanji()\n    paste0(\"Number of kanji: \", number_kanji)\n  })\n  \n  # output number sentences ####\n  output$n_sentences &lt;- renderText({\n    number_sentences &lt;- rval_n_sentences()\n    paste0(\"Number of sentences: \", number_sentences)\n  })\n  \n  # output table words ####\n  output$table_words &lt;- renderDT({\n    study_table &lt;- rval_table_words()\n    study_table\n  })\n  \n  # output table sentences ####\n  output$table_sentences &lt;- renderDT({\n    study_table &lt;- rval_table_sentences()\n    study_table\n  })\n  \n  # output table counter ####\n  \n  output$number_words_per_kanji &lt;- renderTable({\n    table_counter &lt;- rval_table_counter()\n    table_counter\n  })\n  \n  # download Excel ####\n  \n  output$downloadExcel &lt;- downloadHandler(\n    \n    filename = function() {\n      paste0(\"study_list_k\", rval_n_kanji(), \"_w\", rval_n_words(),\".xlsx\")\n    },\n    content = function(file) {\n      write_xlsx(rval_table_words(), file)\n      \n    })\n  \n  # download CSV ####\n  \n  output$downloadCSV &lt;- downloadHandler(\n    \n    filename = function() {\n      paste0(\"study_list_k\", rval_n_kanji(), \"_w\", rval_n_words(),\".csv\")\n    },\n    content = function(file) {\n      write_csv(rval_table_words(), file)\n      \n    })\n\n}\n\n\nshinyApp(ui = ui, server = server)\n\n\nThis code defines a Shiny web application that allows users to generate lists of Japanese words and sentences containing specific kanji characters they want to learn. Here’s an explanation of the key components:\n\nUser Interface Definition (ui):\n\n\nThe UI is defined using fluidPage layout.\nIt consists of a title panel, a sidebar layout with a sidebar panel containing download buttons and a select input to choose kanji characters, and a main panel containing tabs to display the lists of words and sentences.\nThe tabs include a list of words, a list of sentences, and a stats tab.\nVarious output elements like text, tables, and DT (DataTables) are defined to display data.\n\n\nServer Logic (server):\n\n\nThe server logic defines the functionality of the Shiny app.\nIt contains reactive expressions to dynamically update the output elements based on user input.\nIt defines functions to generate lists of words and sentences based on selected kanji characters (make_study_list and make_sentences_list).\nIt calculates the number of occurrences of each kanji character in the selected words and displays them in a table on the “Stats” tab.\nIt provides output functions to display the generated lists of words and sentences.\nIt includes download handlers to allow users to download the generated lists in Excel and CSV formats.\n\n\nShinyApp function:\n\n\nThe shinyApp function combines the UI and server logic to create the Shiny application.\n\nOverall, this Shiny app provides an interactive interface for users to explore and download lists of Japanese words and sentences containing specific kanji characters they are interested in learning."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html",
    "href": "posts/alluvial_plot_stata/post.html",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "",
    "text": "In this post, I explain how to create an alluvial plot using code in Stata.\n\n\nAn alluvial diagram or plot displays the flow of information from one categorical variable or stage to the next. The term “alluvial” refers to its resemblance to the flow of a river.\n\n\n\nAlluvial diagrams are commonly used in the following situations:\n\nTo demonstrate the number of participants in a study transitioning from one baseline category to a subsequent category. For example, the number of participants randomized at the beginning of the study and who continue to follow-up at the end. It serves as a graphical supplement to flowcharts, which present information with arrows and boxes containing text and numbers.\nTo show the distribution of participants among different categorical variables. In this case, it provides a more “visually appealing” alternative to stacked column charts."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#qué-es-un-diagrama-aluvial",
    "href": "posts/alluvial_plot_stata/post.html#qué-es-un-diagrama-aluvial",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "",
    "text": "Un diagrama o gráfico aluvial muestra el flujo de información de un estadio al siguiente. El nombre “aluvial” alude a su parecido con el flujo de un río."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#para-qué-se-usan-los-diagramas-aluviales",
    "href": "posts/alluvial_plot_stata/post.html#para-qué-se-usan-los-diagramas-aluviales",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "",
    "text": "Un diagrama aluvial se suele utilizar en las siguientes situaciones:\n\nPara mostrar el número de participantes de un estudio que cambian desde una categoría basal a una categoría siguiente. Por ejemplo, el número de participantes aleatorizados al principio del estudio y que continúan en seguimiento al final. Es un complemento gráfico a los diagramas de flujo, que presentan la información con flechas y cajas con texto y números.\nPara mostrar la distribución de participantes entre distintas variables categóricas. En este caso es una alternativa más “vistosa” a los diagramas de columnas apilados."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#preparativos",
    "href": "posts/alluvial_plot_stata/post.html#preparativos",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "Preparativos",
    "text": "Preparativos\nPara este ejemplo, usaremos el comando alluvial, que necesita la instalación de los comandos palettes y colrspace y ggplot2. Los datos son una simulación de una comparación de dos tests diagnósticos ficticios, llamados “Test A” y “Test B”, que pueden tener como valor “1-very low”, “2-low”, “3-medium”, “4-high”, y “5-very high”.\n\n\nShow the code\n// Install user-written commands\nnet install alluvial, from(\"https://raw.githubusercontent.com/asjadnaqvi/stata-alluvial/main/installation/\") replace\nssc install palettes, replace\nssc install colrspace, replace\n\n// Input data\nclear\n\ninput test_b test_a\n    4   4\n    1   1\n    1   1\n    2   2\n    3   1\n    1   2\n    3   2\n    2   2\n    5   2\n    3   1\n    3   3\n    3   3\n    5   3\n    4   3\n    1   1\n    3   3\n    4   1\n    2   3\n    5   2\n    4   2\n    4   2\n    2   1\n    5   3\n    3   3\n    5   1\n    3   3\nend\n\n// Label data\n\nlabel var test_a \"Test A\"\nlabel var test_b \"Test B\"\n\nlabel define high_low 1 \"1-very low\" 2 \"2-low\" 3 \"3-medium\" 4 \"4-high\" 5 \"5-very high\", replace\nlabel values test_a test_b high_low\n\n// Tabulate\n\ntab test_a test_b\n\n\n\n\n\n\n\n            |                   Test B\n     Test A | 1-very lo      2-low   3-medium     4-high |     Total\n------------+--------------------------------------------+----------\n 1-very low |         3          1          2          1 |         8 \n      2-low |         1          2          1          2 |         8 \n   3-medium |         0          1          5          1 |         9 \n     4-high |         0          0          0          1 |         1 \n------------+--------------------------------------------+----------\n      Total |         4          4          8          5 |        26 \n\n\n            |   Test B\n     Test A | 5-very hi |     Total\n------------+-----------+----------\n 1-very low |         1 |         8 \n      2-low |         2 |         8 \n   3-medium |         2 |         9 \n     4-high |         0 |         1 \n------------+-----------+----------\n      Total |         5 |        26 \n\n\nEn este estudio ficticio, un total de 26 personas fueron sometidas a los dos tests diagnósticos. Podemos ver en la tabla que tres personas obtuvieron un resultado “very low” en ambos tests, que una persona obtuvo un resultado “very low” en el test A y “low” en el test B, etc.\nLa tabla en sí misma es informativa, pero no permite extraer información de forma rápida e intuitiva. Aquí es donde entra el alluvial plot."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#gráfico",
    "href": "posts/alluvial_plot_stata/post.html#gráfico",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "Gráfico",
    "text": "Gráfico\n\n\nShow the code\n// Alluvial plot\n\nalluvial test_a test_b, palette(RdYlBu, n(5)) labangle(0) novalues boxwidth(5) offset(10) title(\"Alluvial plot of results of Test A vs Test B.\", size(3)) note (\"N = 26\") graphregion(color(white)) showtot lwidth(0.01) lcolor(gray) labpos(3)\n\nqui: graph export fig1.svg, width(1600) replace\n\n\n\n\n\nalluvial_plot\n\n\nIn the alluvial diagram, the area of the colored zones is proportional to the frequency, so wider “flows” represent more participants.\nThe graph shows how there is a considerable “transfer” of participants between result levels in the two tests. For example, we see that slightly less than half of those with a “very low” result in Test A also obtained “very low” in Test B, but others obtained “low”, “medium”, “high”, and even “very high” results. We also clearly see how there are no participants with “very high” results in Test A, or that the only participant with a “high” result in Test A also had a “high” result in Test B.\nIn conclusion, alluvial diagrams provide a visual option for better understanding data flows between categories."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#what-is-an-alluvial-diagram",
    "href": "posts/alluvial_plot_stata/post.html#what-is-an-alluvial-diagram",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "",
    "text": "An alluvial diagram or plot displays the flow of information from one categorical variable or stage to the next. The term “alluvial” refers to its resemblance to the flow of a river."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#uses-of-alluvial-diagrams",
    "href": "posts/alluvial_plot_stata/post.html#uses-of-alluvial-diagrams",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "",
    "text": "Alluvial diagrams are commonly used in the following situations:\n\nTo demonstrate the number of participants in a study transitioning from one baseline category to a subsequent category. For example, the number of participants randomized at the beginning of the study and who continue to follow-up at the end. It serves as a graphical supplement to flowcharts, which present information with arrows and boxes containing text and numbers.\nTo show the distribution of participants among different categorical variables. In this case, it provides a more “visually appealing” alternative to stacked column charts."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#preparations",
    "href": "posts/alluvial_plot_stata/post.html#preparations",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "Preparations",
    "text": "Preparations\nFor this example, we will use the alluvial command, which requires the installation of the palettes and colrspace commands. The data is a simulation of a comparison of two fictional diagnostic tests, called “Test A” and “Test B”, which can take values such as “1-very low”, “2-low”, “3-medium”, “4-high”, and “5-very high”.\n\n\nShow the code\n// Install user-written commands\nnet install alluvial, from(\"https://raw.githubusercontent.com/asjadnaqvi/stata-alluvial/main/installation/\") replace\nssc install palettes, replace\nssc install colrspace, replace\n\n\n\n\nShow the code\n// Input data\nclear\n\ninput test_b test_a\n    4   4\n    1   1\n    1   1\n    2   2\n    3   1\n    1   2\n    3   2\n    2   2\n    5   2\n    3   1\n    3   3\n    3   3\n    5   3\n    4   3\n    1   1\n    3   3\n    4   1\n    2   3\n    5   2\n    4   2\n    4   2\n    2   1\n    5   3\n    3   3\n    5   1\n    3   3\nend\n\n// Label data\n\nlabel var test_a \"Test A\"\nlabel var test_b \"Test B\"\n\nlabel define high_low 1 \"1-very low\" 2 \"2-low\" 3 \"3-medium\" 4 \"4-high\" 5 \"5-very high\", replace\nlabel values test_a test_b high_low\n\n// Tabulate\n\ntab test_a test_b\n\n\n\n\n            |                   Test B\n     Test A | 1-very lo      2-low   3-medium     4-high |     Total\n------------+--------------------------------------------+----------\n 1-very low |         3          1          2          1 |         8 \n      2-low |         1          2          1          2 |         8 \n   3-medium |         0          1          5          1 |         9 \n     4-high |         0          0          0          1 |         1 \n------------+--------------------------------------------+----------\n      Total |         4          4          8          5 |        26 \n\n\n            |   Test B\n     Test A | 5-very hi |     Total\n------------+-----------+----------\n 1-very low |         1 |         8 \n      2-low |         2 |         8 \n   3-medium |         2 |         9 \n     4-high |         0 |         1 \n------------+-----------+----------\n      Total |         5 |        26 \n\n\nIn this fictional study, a total of 26 people underwent both diagnostic tests. We can see in the table that three people obtained a “very low” result in both tests, one person obtained a “very low” result in test A and “low” in test B, etc.\nThe table itself is informative but does not allow for quick and intuitive information extraction. This is where the alluvial plot comes in."
  },
  {
    "objectID": "posts/alluvial_plot_stata/post.html#alluvial-plot",
    "href": "posts/alluvial_plot_stata/post.html#alluvial-plot",
    "title": "How to Create an Alluvial Plot in Stata",
    "section": "Alluvial Plot",
    "text": "Alluvial Plot\n\n\nShow the code\n// Alluvial plot\n\nalluvial test_a test_b, palette(RdYlBu, n(5)) labangle(0) novalues boxwidth(5) offset(10) title(\"Alluvial plot of results of Test A vs Test B.\", size(3)) note (\"N = 26\") graphregion(color(white)) showtot lwidth(0.01) lcolor(gray) labpos(3)\n\nqui: graph export fig1.svg, width(1600) replace\n\n\n\n\n\nalluvial_plot\n\n\nIn the alluvial diagram, the area of the colored zones is proportional to the frequency, so wider “flows” represent more participants.\nThe graph shows how there is a considerable “transfer” of participants between result levels in the two tests. For example, we see that slightly less than half of those with a “very low” result in Test A also obtained “very low” in Test B, but others obtained “low”, “medium”, “high”, and even “very high” results. We also clearly see how there are no participants with “very high” results in Test A, or that the only participant with a “high” result in Test A also had a “high” result in Test B.\nIn conclusion, alluvial diagrams provide a visual option for better understanding data flows between categories."
  },
  {
    "objectID": "posts/alluvial_plot/post.html#what-is-an-alluvial-diagram",
    "href": "posts/alluvial_plot/post.html#what-is-an-alluvial-diagram",
    "title": "How to Create an Aluvial Plot in R",
    "section": "",
    "text": "An alluvial diagram or plot displays the flow of information from one categorical variable or stage to the next. The term “alluvial” refers to its resemblance to the flow of a river."
  },
  {
    "objectID": "posts/alluvial_plot/post.html#uses-of-alluvial-diagrams",
    "href": "posts/alluvial_plot/post.html#uses-of-alluvial-diagrams",
    "title": "How to Create an Aluvial Plot in R",
    "section": "",
    "text": "Alluvial diagrams are commonly used in the following situations:\n\nTo demonstrate the number of participants in a study transitioning from one baseline category to a subsequent category. For example, the number of participants randomized at the beginning of the study and who continue to follow-up at the end. It serves as a graphical supplement to flowcharts, which present information with arrows and boxes containing text and numbers.\nTo show the distribution of participants among different categorical variables. In this case, it provides a more “visually appealing” alternative to stacked column charts."
  },
  {
    "objectID": "posts/alluvial_plot/post.html#alluvial-plot",
    "href": "posts/alluvial_plot/post.html#alluvial-plot",
    "title": "How to Create an Aluvial Plot in R",
    "section": "Alluvial Plot",
    "text": "Alluvial Plot\n\n\nShow the code\ndata %&gt;% \nggplot(aes(axis1 = fct_rev(Initial), axis2 = fct_rev(Final),\n           y = Frequency)) +\n  scale_x_discrete(limits = c(\"Initial\", \"Final\"), expand = c(.2, .05)) +\n  geom_alluvium(aes(fill = Final)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_minimal() +\n  labs(x = \"Equivalent formal education semesters\")\n\n\n\n\n\nIn the alluvial diagram, the area of the colored zones is proportional to the frequency, so wider “flows” represent more participants.\nThe graph shows how the majority of the flow occurs from bottom to top; that is, knowledge tends to improve more than deteriorate. For example, more than half of the participants who started from the first semester of knowledge progressed to the second, third, or fourth semester.\nIt can also be seen that almost all participants who ended with a knowledge level equivalent to the first semester started from that previous level, and a few decreased from the second semester to the first semester.\nIn conclusion, alluvial diagrams provide a visual option for better understanding data flows between categories."
  },
  {
    "objectID": "posts/lasso_regression/post.html#fitting-the-model",
    "href": "posts/lasso_regression/post.html#fitting-the-model",
    "title": "Lasso Regression",
    "section": "Fitting the Model",
    "text": "Fitting the Model\n\n\nShow the code\n# Model coefficients\nbest_model &lt;- glmnet(x, y, alpha = 1, lambda = best_lambda)\ncoef(best_model)\n\n\n6 x 1 sparse Matrix of class \"dgCMatrix\"\n                     s0\n(Intercept) 35.99744772\ncyl         -0.85518839\nhp          -0.01598015\nwt          -2.88233444\ndrat         0.27858106\ngear         .         \n\n\nWe can observe that the coefficient of gear appears as a point, indicating that the Lasso regression has eliminated the coefficient since the variable was not important enough."
  },
  {
    "objectID": "posts/lasso_regression/post.html#comparison-with-linear-regression-without-lasso",
    "href": "posts/lasso_regression/post.html#comparison-with-linear-regression-without-lasso",
    "title": "Lasso Regression",
    "section": "Comparison with Linear Regression without Lasso",
    "text": "Comparison with Linear Regression without Lasso\nFor comparison, we can see the coefficients that would result from a multiple linear regression model without parameter shrinkage or variable selection.\n\n\nShow the code\nlinear_model &lt;- lm(mpg ~ cyl + hp + wt + drat + gear, data = mtcars)\nmodel_table &lt;- cbind(coef(best_model), coef(linear_model))\ncolnames(model_table) &lt;- c(\"Lasso\", \"Linear\")\nmodel_table\n\n\n6 x 2 sparse Matrix of class \"dgCMatrix\"\n                  Lasso      Linear\n(Intercept) 35.99744772 33.99417771\ncyl         -0.85518839 -0.72169272\nhp          -0.01598015 -0.02227636\nwt          -2.88233444 -2.92715539\ndrat         0.27858106  0.73105753\ngear         .           0.16750690\n\n\nThe coefficients of the Lasso model have been shrunk slightly, especially for the drat variable, and the gear variable has been automatically excluded."
  },
  {
    "objectID": "posts/kanji_app/post.html#custom-functions-to-create-the-study-table",
    "href": "posts/kanji_app/post.html#custom-functions-to-create-the-study-table",
    "title": "Interactive List of Japanese Words Using R Shiny Apps",
    "section": "Custom Functions to Create the Study Table",
    "text": "Custom Functions to Create the Study Table\n\n\nShow the code\n# Functions ####\n\nmake_study_list &lt;- function(kanji_learning) {\n  \n  # Select words with only those kanji\n  study_words &lt;- data_all %&gt;% \n    filter(kanji_1 %in% kanji_learning,  \n             kanji_2 %in% kanji_learning | is.na(kanji_2),\n             kanji_3 %in% kanji_learning | is.na(kanji_3),\n             kanji_4 %in% kanji_learning | is.na(kanji_4),\n             kanji_5 %in% kanji_learning | is.na(kanji_5)) %&gt;% \n    select(!starts_with(\"kanji_\"))\n  \n  study_words\n}\n\n\nmake_sentences_list &lt;- function(kanji_learning) {\n  \n  kanji_list &lt;- paste(kanji_learning, collapse = \"|\")\n  \n  letters_lower &lt;- paste(letters, collapse = \"|\")\n  letters_upper &lt;- paste(LETTERS, collapse = \"|\")\n  numbers &lt;- paste(0:9, collapse = \"|\")\n  symbols &lt;- \"。|、|「|」|？|!|%|！|々\"\n  \n  other_characters &lt;- paste(c(letters_lower, letters_upper, numbers, symbols), collapse = \"|\")\n  \n  sentences_list &lt;- data_sentences %&gt;% \n    mutate(only_kanji = str_remove_all(sentence, paste(kana, other_characters, sep = \"|\")),\n           unknown_kanji = str_remove_all(only_kanji, kanji_list)) %&gt;% \n    filter(unknown_kanji == \"\", grepl(kanji_list, sentence)) %&gt;% \n    select(sentence, sentence_hiragana, sentence_meaning)\n  \n  sentences_list\n  \n}\n\n\nThis code defines two functions: make_study_list and make_sentences_list. Let’s break down what each function does:\n\nmake_study_list function:\n\n\nInput: kanji_learning is a vector containing the kanji characters that the user wants to learn.\nOutput: study_words is a data frame containing words from data_all dataset that contain only the kanji characters specified in kanji_learning.\nFunctionality:\n\nFilters the data_all dataset to select words that contain only the kanji characters specified in kanji_learning.\nThis is done by filtering the rows where each kanji column (kanji_1, kanji_2, kanji_3, kanji_4, kanji_5) matches one of the kanji characters in kanji_learning, or where the kanji column is NA (missing).\nRemoves the kanji_ columns from the resulting dataset.\nReturns the filtered dataset containing only the selected words.\n\n\n\nmake_sentences_list function:\n\n\nInput: kanji_learning is a vector containing the kanji characters that the user wants to learn.\nOutput: sentences_list is a data frame containing sentences from data_sentences dataset that contain kanji characters specified in kanji_learning.\nFunctionality:\n\nConcatenates the kanji characters in kanji_learning into a single regular expression pattern kanji_list.\nDefines regular expression patterns for lowercase letters, uppercase letters, numbers, and symbols.\nUses these patterns to define other_characters, which includes all characters that are not kanji.\nFor each sentence in data_sentences, removes all characters that are not kanji, then removes all kanji characters that are not in kanji_learning.\nFilters the sentences to keep only those that contain kanji characters specified in kanji_learning.\nSelects the filtered sentences along with their corresponding hiragana representation and meaning.\n\nNote: The str_remove_all function from the stringr package is used to remove all occurrences of a pattern from a string.\n\nThese functions are designed to help users generate study lists of words and sentences containing specific kanji characters they want to learn."
  }
]